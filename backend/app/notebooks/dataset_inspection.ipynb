{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET INSPECTION\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define metadata path and image directories\n",
    "metadata_path = r'D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "image_dir_1 = r'D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_1'\n",
    "image_dir_2 = r'D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_2'\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(\"##### Inspect The First Few Rows #####\")\n",
    "print(metadata.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check data types\n",
    "data_types = metadata.dtypes\n",
    "print(\"##### Data Types ##### \\n\", data_types)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = metadata.isnull().sum()\n",
    "print(\"##### Missing Values In Columns ##### \\n\", missing_values)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check Unknown Valuses In \"SEX\" and \"LOCALIZATION\" Columns\n",
    "print(\"##### Checking 'unknown' values in 'SEX' and 'LOCALIZATION' columns #####\")\n",
    "if 'unknown' in metadata['sex'].values:\n",
    "    print(\"'unknown' exists in 'sex' column.\")\n",
    "else:\n",
    "    print(\"'unknown' does not exist in 'sex' column.\")\n",
    "\n",
    "if 'unknown' in metadata['localization'].values:\n",
    "    print(\"'unknown' exists in 'localization' column.\")\n",
    "else:\n",
    "    print(\"'unknown' does not exist in 'localization' column.\")\n",
    "\n",
    "# Check for duplicate rows in metadata\n",
    "print(\"\\n\")\n",
    "print(\"##### Checking Duplicate Rows #####\")\n",
    "duplicate_count = metadata.duplicated().sum()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Duplicate rows found: {duplicate_count}. Removing duplicates...\")\n",
    "    # metadata.drop_duplicates(inplace=True)\n",
    "    # print(\"Duplicate rows removed.\")\n",
    "else:\n",
    "    print(\"No duplicate rows found. No action taken.\")\n",
    "\n",
    "# Verify that all images listed in the metadata are present in the folders\n",
    "print(\"\\n\")\n",
    "print(\"##### Checking Missing Images In Folders #####\")\n",
    "image_ids = set(metadata['image_id'])\n",
    "all_image_files = set(os.listdir(image_dir_1) + os.listdir(image_dir_2))\n",
    "missing_images = [img_id for img_id in image_ids if f\"{img_id}.jpg\" not in all_image_files]\n",
    "if missing_images:\n",
    "    print(f\"Missing images: {missing_images}\")\n",
    "else:\n",
    "    print(\"All images are accounted for.\")\n",
    "\n",
    "# Check for duplicate image_id values\n",
    "print(\"\\n\")\n",
    "# Check for rows with age = 0.0\n",
    "print(\"##### Checking for invalid ages (0.0) #####\")\n",
    "invalid_age_rows = metadata[metadata['age'] == 0.0]\n",
    "print(f\"Number of rows with invalid age: {len(invalid_age_rows)}\")\n",
    "\n",
    "if len(invalid_age_rows) > 0:\n",
    "    print(\"\\nRows with invalid age:\")\n",
    "    print(invalid_age_rows)  # Display all rows with invalid age\n",
    "else:\n",
    "    print(\"No invalid ages found.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Basic statistics of the dataset\n",
    "print(\"\\n\")\n",
    "print(\"##### Statistics of the dataset #####\")\n",
    "print(metadata.describe(include='all'))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET VISUALIZATION\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "metadata_path = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "image_dir_1 = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_1'\n",
    "image_dir_2 = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_2'\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Visualize the distribution of diseases\n",
    "print(\"\\n\")\n",
    "print(\"##### Displaying Distribution of Diseases (Lesion) #####\")\n",
    "sns.countplot(data=metadata, x='dx')\n",
    "plt.title(\"Distribution of Skin Diseases in HAM10000 Dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Display sample images\n",
    "print(\"##### Displaying sample images #####\")\n",
    "def display_sample_images(image_dir, num_samples=5):\n",
    "    sample_files = os.listdir(image_dir)[:num_samples]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, filename in enumerate(sample_files):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path)\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_sample_images(image_dir_1)\n",
    "display_sample_images(image_dir_2)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Additional Checks and Visualizations\n",
    "\n",
    "# Correlation Analysis\n",
    "numeric_metadata = metadata.select_dtypes(include=['float64', 'int64'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numeric_metadata.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Outliers Detection\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='age', data=metadata)\n",
    "plt.title('Age Outliers')\n",
    "plt.show()\n",
    "\n",
    "# Data Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.pairplot(metadata, hue='dx')\n",
    "plt.title('Pairplot of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET MANIPULATION\n",
    "\n",
    "import pandas as pd\n",
    "# Define metadata path and image directories\n",
    "metadata_path = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# HANDLING [ UNKNOWN, MISING] VALUES IN \"SEX\" AND \"LOCALIZATION\" COLUMNS\n",
    "if 'unknown' in metadata['sex'].values:\n",
    "    metadata['sex'].replace('unknown', metadata['sex'].mode()[0], inplace=True)\n",
    "    print(f\"'unknown' in 'sex' replaced with mode: {metadata['sex'].mode()[0]}\")\n",
    "\n",
    "if 'unknown' in metadata['localization'].values:\n",
    "    metadata['localization'].replace('unknown', metadata['localization'].mode()[0], inplace=True)\n",
    "    print(f\"'unknown' in 'localization' replaced with mode: {metadata['localization'].mode()[0]}\")\n",
    "\n",
    "# Check for rows with age = 0.0\n",
    "print(\"##### Checking for invalid ages (0.0) #####\")\n",
    "invalid_age_rows = metadata[metadata['age'] == 0.0]\n",
    "print(f\"Number of rows with invalid age: {len(invalid_age_rows)}\")\n",
    "\n",
    "if len(invalid_age_rows) > 0:\n",
    "    print(\"\\nRows with invalid age:\")\n",
    "    print(invalid_age_rows)  # Display all rows with invalid age\n",
    "\n",
    "    # Replace 0.0 with the median age\n",
    "    median_age = metadata[metadata['age'] > 0.0]['age'].median()\n",
    "    metadata['age'] = metadata['age'].replace(0.0, median_age)\n",
    "    print(f\"Invalid ages replaced with the median age: {median_age:.2f}\")\n",
    "else:\n",
    "    print(\"No invalid ages found.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Save the cleaned metadata\n",
    "metadata.to_csv(metadata_path, index=False)\n",
    "print(\"Cleaned metadata saved to metadata.csv : {metadata_path}\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING CLASS WEIGHTS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "metadata_path = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "dataset = pd.read_csv(metadata_path)\n",
    "labels = dataset['dx']\n",
    "\n",
    "print(labels.head())\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define class labels and counts from your dataset\n",
    "classes = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n",
    "class_counts = [1099, 6705, 115, 1113, 142, 514, 327]  # Replace with your dataset values\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Class Weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VISUALIZATION : CLASS DISTRIBUTION PLOT DATA2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "def plot_class_distribution(dataset_path):\n",
    "    \"\"\"\n",
    "    Visualizes the class distribution from the dataset folder structure.\n",
    "    \n",
    "    :param dataset_path: Path to the dataset directory containing class subfolders.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    \n",
    "    # Iterate through each class folder\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_counts[class_name] = len(os.listdir(class_folder))\n",
    "    \n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"viridis\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.title(\"Dataset Class Distribution\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (update with your actual dataset path)\n",
    "dataset_path = r\"D:\\skin_disease_detection\\backend\\data2\\base_dir\\train_dir\"\n",
    "plot_class_distribution(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCREASE CLASSES 200 PLUS FOR BALANCE VAL_DIR IN DATA2\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_images_balanced(val_dir, target_count=500, max_variants_per_image=5):\n",
    "    \"\"\"\n",
    "    Augments images inside val_dir while ensuring balanced class distribution.\n",
    "    - Each class will have at least `target_count` images.\n",
    "    - Prevents excessive duplication from a single image.\n",
    "    - Saves augmented images with `_X_randomnumber.jpg` format (X = class 0-6).\n",
    "    \"\"\"\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "\n",
    "    for class_index, class_name in enumerate(os.listdir(val_dir)):\n",
    "        class_path = os.path.join(val_dir, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-folder files\n",
    "\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "        num_existing = len(images)\n",
    "\n",
    "        if num_existing >= target_count:\n",
    "            print(f\"Skipping {class_name}, already has {num_existing} images.\")\n",
    "            continue\n",
    "\n",
    "        num_needed = target_count - num_existing\n",
    "        print(f\"Generating {num_needed} images for class: {class_name}\")\n",
    "\n",
    "        # Determine how many times each image should be augmented\n",
    "        augmentation_distribution = np.full(len(images), num_needed // len(images))\n",
    "        augmentation_distribution[:num_needed % len(images)] += 1  # Spread remainder\n",
    "\n",
    "        for img_path, aug_count in zip(images, augmentation_distribution):\n",
    "            if aug_count == 0:\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "            i = 0\n",
    "            for batch in datagen.flow(img, batch_size=1):\n",
    "                random_number = np.random.randint(10000, 99999)\n",
    "                filename = f\"_{class_index}_{random_number}.jpg\"\n",
    "                save_path = os.path.join(class_path, filename)\n",
    "\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(batch[0].astype('uint8'), cv2.COLOR_RGB2BGR))\n",
    "                i += 1\n",
    "                if i >= aug_count or i >= max_variants_per_image:\n",
    "                    break  # Prevent excessive augmentation per image\n",
    "\n",
    "    print(\"Augmentation completed.\")\n",
    "\n",
    "# Example usage:\n",
    "val_directory = r\"D:\\skin_disease_detection\\backend\\data2\\base_dir\\val_dir\"\n",
    "augment_images_balanced(val_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCREASE CLASSES WHOSE LESS THAN 200 AND BALANCE VAL_DIR IN DATA2\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_images_balanced(val_dir, min_target=450, max_variants_per_image=10):\n",
    "    \"\"\"\n",
    "    Augments images in `val_dir` to ensure every class has at least `min_target` images.\n",
    "    - Classes with fewer images will get more augmentation.\n",
    "    - Limits excessive duplication per image using `max_variants_per_image`.\n",
    "    \"\"\"\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "\n",
    "    for class_index, class_name in enumerate(os.listdir(val_dir)):\n",
    "        class_path = os.path.join(val_dir, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-folder files\n",
    "\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "        num_existing = len(images)\n",
    "\n",
    "        if num_existing >= min_target:\n",
    "            print(f\"‚úÖ Skipping {class_name}, already has {num_existing} images.\")\n",
    "            continue\n",
    "\n",
    "        num_needed = min_target - num_existing\n",
    "        print(f\"üîÑ Generating {num_needed} images for class: {class_name}\")\n",
    "\n",
    "        # Adjust max augmentations per image based on how few images we have\n",
    "        per_image_limit = min(max_variants_per_image, (num_needed // max(1, num_existing)) + 1)\n",
    "\n",
    "        for img_path in images:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "            i = 0\n",
    "            for batch in datagen.flow(img, batch_size=1):\n",
    "                random_number = np.random.randint(10000, 99999)\n",
    "                filename = f\"_{class_index}_{random_number}.jpg\"\n",
    "                save_path = os.path.join(class_path, filename)\n",
    "\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(batch[0].astype('uint8'), cv2.COLOR_RGB2BGR))\n",
    "                i += 1\n",
    "                if i >= per_image_limit:\n",
    "                    break  # Stop once enough images are generated\n",
    "\n",
    "    print(\"‚úÖ Augmentation completed with balanced validation set.\")\n",
    "\n",
    "# Example usage:\n",
    "val_directory = r\"D:\\skin_disease_detection\\backend\\data2\\base_dir\\val_dir\"\n",
    "augment_images_balanced(val_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING DATASET INTO TRAIN, VALIDATION, AND TEST SETS USING ORIGINAL HAM10000 DATASET\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define paths\n",
    "BASE_DIR = r\"D:\\skin_disease_detection\\backend\\data\\Ham10000\"\n",
    "IMAGES_DIR_1 = os.path.join(BASE_DIR, \"HAM10000_images_part_1\")\n",
    "IMAGES_DIR_2 = os.path.join(BASE_DIR, \"HAM10000_images_part_2\")\n",
    "METADATA_FILE = os.path.join(BASE_DIR, \"HAM10000_metadata.csv\")\n",
    "\n",
    "# Define new dataset structure\n",
    "OUTPUT_DIR = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\"\n",
    "TRAIN_DIR = os.path.join(OUTPUT_DIR, \"train_dir\")\n",
    "VAL_DIR = os.path.join(OUTPUT_DIR, \"val_dir\")\n",
    "TEST_DIR = os.path.join(OUTPUT_DIR, \"test_dir\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "for split_dir in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    for class_name in [\"akiec\", \"bcc\", \"bkl\", \"df\", \"mel\", \"nv\", \"vasc\"]:\n",
    "        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(METADATA_FILE)\n",
    "\n",
    "# Combine image paths\n",
    "metadata[\"image_path\"] = metadata[\"image_id\"].apply(\n",
    "    lambda x: os.path.join(IMAGES_DIR_1, x + \".jpg\") if os.path.exists(os.path.join(IMAGES_DIR_1, x + \".jpg\"))\n",
    "    else os.path.join(IMAGES_DIR_2, x + \".jpg\")\n",
    ")\n",
    "\n",
    "# Split dataset (70% train, 20% val, 10% test) ensuring no overlap\n",
    "train_data, temp_data = train_test_split(metadata, test_size=0.3, stratify=metadata[\"dx\"], random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=1/3, stratify=temp_data[\"dx\"], random_state=42)\n",
    "\n",
    "def copy_images(df, dest_dir):\n",
    "    \"\"\" Copy images to the respective directory \"\"\"\n",
    "    for _, row in df.iterrows():\n",
    "        label = row[\"dx\"]  # Lesion label\n",
    "        src_path = row[\"image_path\"]\n",
    "        dest_path = os.path.join(dest_dir, label, os.path.basename(src_path))\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Copy images to respective directories\n",
    "copy_images(train_data, TRAIN_DIR)\n",
    "copy_images(val_data, VAL_DIR)\n",
    "copy_images(test_data, TEST_DIR)\n",
    "\n",
    "print(\"Dataset successfully split into train, validation, and test sets without overlap!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING INTERSECTION BETWEEN TRAIN, VAL, AND TEST DIRECTORIES\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define dataset paths\n",
    "METADATA_FILE = r\"D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv\"\n",
    "TRAIN_DIR = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\train_dir\"\n",
    "VAL_DIR = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\val_dir\"\n",
    "TEST_DIR = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\test_dir\"\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(METADATA_FILE)\n",
    "\n",
    "# Function to get image IDs from directory\n",
    "def get_image_ids(directory):\n",
    "    image_ids = set()\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            for image in os.listdir(class_path):\n",
    "                image_id = os.path.splitext(image)[0]  # Remove file extension\n",
    "                image_ids.add(image_id)\n",
    "    return image_ids\n",
    "\n",
    "# Get image IDs from each dataset\n",
    "train_ids = get_image_ids(TRAIN_DIR)\n",
    "val_ids = get_image_ids(VAL_DIR)\n",
    "test_ids = get_image_ids(TEST_DIR)\n",
    "\n",
    "# Check for intersections\n",
    "train_val_intersection = train_ids.intersection(val_ids)\n",
    "train_test_intersection = train_ids.intersection(test_ids)\n",
    "val_test_intersection = val_ids.intersection(test_ids)\n",
    "\n",
    "# Print results\n",
    "if not train_val_intersection and not train_test_intersection and not val_test_intersection:\n",
    "    print(\"No intersections found between train, val, and test sets. Data split is clean.\")\n",
    "else:\n",
    "    if train_val_intersection:\n",
    "        print(f\"Train-Val Intersection Detected: {len(train_val_intersection)} images\")\n",
    "    if train_test_intersection:\n",
    "        print(f\"Train-Test Intersection Detected: {len(train_test_intersection)} images\")\n",
    "    if val_test_intersection:\n",
    "        print(f\"Val-Test Intersection Detected: {len(val_test_intersection)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCING TRAIN_DIR DATASET USING ALBUMENTATIONS - own_data\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "\n",
    "# Define the train directory\n",
    "TRAIN_DIR = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\train_dir\"\n",
    "\n",
    "# Define class sample counts\n",
    "class_counts = {\n",
    "    \"akiec\": 229,\n",
    "    \"bcc\": 360,\n",
    "    \"bkl\": 769,\n",
    "    \"df\": 81,\n",
    "    \"mel\": 779,\n",
    "    \"nv\": 4693,  # Maximum samples\n",
    "    \"vasc\": 99\n",
    "}\n",
    "\n",
    "MAX_SAMPLES = max(class_counts.values())\n",
    "\n",
    "# Define Albumentations augmentation pipeline\n",
    "AUGMENTATION = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, border_mode=cv2.BORDER_REFLECT, p=0.7),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),\n",
    "    A.Resize(height=224, width=224, p=1.0)  # Resizing to 512x512 for better feature retention\n",
    "])\n",
    "\n",
    "def augment_image(image_path, output_path):\n",
    "    \"\"\"Applies advanced augmentation using Albumentations and saves the image.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    augmented = AUGMENTATION(image=image)['image']\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def balance_classes():\n",
    "    \"\"\"Balances the dataset by oversampling minority classes to reach MAX_SAMPLES.\"\"\"\n",
    "    for class_name, count in class_counts.items():\n",
    "        class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "        images = [img for img in os.listdir(class_dir) if img.endswith(\".jpg\")]\n",
    "        num_images = len(images)\n",
    "        \n",
    "        if num_images < MAX_SAMPLES:\n",
    "            needed = MAX_SAMPLES - num_images\n",
    "            print(f\"Oversampling {class_name}: Adding {needed} images.\")\n",
    "            \n",
    "            for i in range(needed):\n",
    "                img_choice = random.choice(images)\n",
    "                src_path = os.path.join(class_dir, img_choice)\n",
    "                new_img_name = f\"aug_{i}_{img_choice}\"\n",
    "                dest_path = os.path.join(class_dir, new_img_name)\n",
    "                \n",
    "                augment_image(src_path, dest_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    balance_classes()\n",
    "    print(\"Train dataset balanced successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCING TRAIN_DIR USING ALBUMENTATIONS - own_data_2\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "\n",
    "# Define the train directory\n",
    "TRAIN_DIR = r\"D:\\skin_disease_detection\\backend\\own_data_2\\base_dir\\train_dir\"\n",
    "\n",
    "# Define class sample counts\n",
    "class_counts = {\n",
    "    \"akiec\": 229,\n",
    "    \"bcc\": 360,\n",
    "    \"bkl\": 769,\n",
    "    \"df\": 81,\n",
    "    \"mel\": 779,\n",
    "    \"nv\": 4693,  # Maximum samples\n",
    "    \"vasc\": 99\n",
    "}\n",
    "\n",
    "# Set a more reasonable target (e.g., Median class size)\n",
    "TARGET_SAMPLES = 2000  # You can tweak this value\n",
    "\n",
    "# Define Albumentations augmentation pipelines\n",
    "WEAK_AUGMENTATION = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=0.3),\n",
    "    A.Resize(height=224, width=224, p=1.0)\n",
    "])\n",
    "\n",
    "STRONG_AUGMENTATION = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=20, border_mode=cv2.BORDER_REFLECT, p=0.7),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.2, p=0.5),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n",
    "    A.Resize(height=224, width=224, p=1.0)\n",
    "])\n",
    "\n",
    "def augment_image(image_path, output_path, use_strong_aug=False):\n",
    "    \"\"\"Applies augmentation using Albumentations and saves the image.\"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    aug_pipeline = STRONG_AUGMENTATION if use_strong_aug else WEAK_AUGMENTATION\n",
    "    augmented = aug_pipeline(image=image)['image']\n",
    "\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "def blend_images(img1_path, img2_path, output_path):\n",
    "    \"\"\"Creates a blended image to add variation (MixUp-like effect).\"\"\"\n",
    "    img1 = cv2.imread(img1_path)\n",
    "    img2 = cv2.imread(img2_path)\n",
    "\n",
    "    if img1 is None or img2 is None:\n",
    "        return\n",
    "\n",
    "    alpha = random.uniform(0.4, 0.6)\n",
    "    blended = cv2.addWeighted(img1, alpha, img2, 1 - alpha, 0)\n",
    "    cv2.imwrite(output_path, blended)\n",
    "\n",
    "def balance_classes():\n",
    "    \"\"\"Balances the dataset by moderate oversampling, avoiding excessive augmentation.\"\"\"\n",
    "    for class_name, count in class_counts.items():\n",
    "        class_dir = os.path.join(TRAIN_DIR, class_name)\n",
    "        images = [img for img in os.listdir(class_dir) if img.endswith(\".jpg\")]\n",
    "        num_images = len(images)\n",
    "\n",
    "        if num_images < TARGET_SAMPLES:\n",
    "            needed = TARGET_SAMPLES - num_images\n",
    "            print(f\"Oversampling {class_name}: Adding {needed} images.\")\n",
    "\n",
    "            for i in range(needed):\n",
    "                img_choice = random.choice(images)\n",
    "                src_path = os.path.join(class_dir, img_choice)\n",
    "                new_img_name = f\"aug_{i}_{img_choice}\"\n",
    "                dest_path = os.path.join(class_dir, new_img_name)\n",
    "\n",
    "                # Apply strong augmentation only for highly imbalanced classes\n",
    "                use_strong_aug = class_counts[class_name] < 500\n",
    "                augment_image(src_path, dest_path, use_strong_aug)\n",
    "\n",
    "                # Occasionally apply blending for more diversity\n",
    "                if i % 5 == 0 and len(images) > 1:\n",
    "                    img2_choice = random.choice(images)\n",
    "                    img2_path = os.path.join(class_dir, img2_choice)\n",
    "                    blend_output = os.path.join(class_dir, f\"blend_{i}_{img_choice}\")\n",
    "                    blend_images(src_path, img2_path, blend_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    balance_classes()\n",
    "    print(\"Train dataset balanced successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGMENT TO INCREASE IMAGES GIVEN TARGET SIZE ANY SINGLE DIR\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "\n",
    "def create_train_transform(target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Creates an Albumentations augmentation pipeline using the given target size.\n",
    "    The pipeline applies a horizontal flip, rotation, brightness/contrast adjustment,\n",
    "    a random resized crop, and finally a resize to guarantee uniform output size.\n",
    "    \"\"\"\n",
    "    height, width = target_size\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=15, p=0.5, border_mode=cv2.BORDER_REFLECT_101, interpolation=cv2.INTER_LINEAR),\n",
    "        A.RandomBrightnessContrast(p=0.2),\n",
    "        A.OneOf([\n",
    "            A.GaussianBlur(blur_limit=3, p=0.2),\n",
    "            A.MotionBlur(blur_limit=3, p=0.2)\n",
    "        ], p=0.3),\n",
    "        A.RandomResizedCrop(size=(height, width), scale=(0.8, 1.0), ratio=(0.75, 1.33), p=0.5),\n",
    "        A.Resize(height=height, width=width)\n",
    "    ])\n",
    "\n",
    "def augment_and_save(input_dir, output_dir, num_aug=1, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Processes all images in the input directory (organized by class) using the \n",
    "    augmentation pipeline and saves augmented images to the output directory.\n",
    "    \n",
    "    Parameters:\n",
    "      - input_dir: Path to your training folder (e.g., .../train_dir)\n",
    "      - output_dir: Folder where augmented images will be stored.\n",
    "      - num_aug: Number of augmented samples to generate per image.\n",
    "      - target_size: Desired output size for the images.\n",
    "    \"\"\"\n",
    "    transform = create_train_transform(target_size)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Assume input_dir has subfolders for each class\n",
    "    classes = sorted(os.listdir(input_dir))\n",
    "    for cls in classes:\n",
    "        class_in_dir = os.path.join(input_dir, cls)\n",
    "        if not os.path.isdir(class_in_dir):\n",
    "            continue\n",
    "        \n",
    "        # Create output folder for the class if it doesn't exist\n",
    "        class_out_dir = os.path.join(output_dir, cls)\n",
    "        if not os.path.exists(class_out_dir):\n",
    "            os.makedirs(class_out_dir)\n",
    "        \n",
    "        # Process each image in the class folder\n",
    "        for img_name in sorted(os.listdir(class_in_dir)):\n",
    "            img_path = os.path.join(class_in_dir, img_name)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"Skipping {img_path} (cannot read)\")\n",
    "                continue\n",
    "            # Convert image from BGR (OpenCV default) to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Generate augmented versions\n",
    "            for i in range(num_aug):\n",
    "                augmented = transform(image=image)\n",
    "                aug_image = augmented['image']\n",
    "                # Convert back to BGR for saving with OpenCV\n",
    "                aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
    "                base_name, ext = os.path.splitext(img_name)\n",
    "                new_name = f\"{base_name}_aug_{i}{ext}\"\n",
    "                out_path = os.path.join(class_out_dir, new_name)\n",
    "                cv2.imwrite(out_path, aug_image_bgr)\n",
    "                print(f\"Saved augmented image: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Change these paths to match your dataset\n",
    "    input_train_dir = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\train_dir\"\n",
    "    output_aug_dir = r\"D:\\skin_disease_detection\\backend\\aug\"\n",
    "    \n",
    "    # Generate 3 augmented images per original image\n",
    "    augment_and_save(input_train_dir, output_aug_dir, num_aug=3, target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schecking visually similar images from all 7 classes in the dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# ==================== 1Ô∏è‚É£ Load Pretrained Model ====================\n",
    "# Load DenseNet121 (without top classification layer)\n",
    "model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "# ==================== 2Ô∏è‚É£ Function to Extract Features ====================\n",
    "def extract_features(img_path):\n",
    "    \"\"\"Extracts feature vector from an image using DenseNet121.\"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = model.predict(img_array)\n",
    "    return features.flatten()\n",
    "\n",
    "# ==================== 3Ô∏è‚É£ Compute Similarity ====================\n",
    "def find_similar_images(image_folder, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Extracts features from all images in the dataset and finds similar ones.\n",
    "    Returns a list of similar image pairs.\n",
    "    \"\"\"\n",
    "    image_features = {}\n",
    "    \n",
    "    # Extract features for each image\n",
    "    for class_name in os.listdir(image_folder):\n",
    "        class_path = os.path.join(image_folder, class_name)\n",
    "        if os.path.isdir(class_path):  # Ensure it's a directory\n",
    "            for img_file in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                features = extract_features(img_path)\n",
    "                image_features[img_path] = (features, class_name)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similar_images = []\n",
    "    image_paths = list(image_features.keys())\n",
    "    \n",
    "    for i in range(len(image_paths)):\n",
    "        for j in range(i + 1, len(image_paths)):\n",
    "            features1, class1 = image_features[image_paths[i]]\n",
    "            features2, class2 = image_features[image_paths[j]]\n",
    "            \n",
    "            # Ensure comparison is between different classes\n",
    "            if class1 != class2:\n",
    "                dist = cosine(features1, features2)\n",
    "                if dist < threshold:  # Smaller distance means more similarity\n",
    "                    similar_images.append((image_paths[i], image_paths[j], class1, class2, dist))\n",
    "    \n",
    "    return sorted(similar_images, key=lambda x: x[4])  # Sort by similarity score\n",
    "\n",
    "# ==================== 4Ô∏è‚É£ Display Confusing Image Pairs ====================\n",
    "def show_confusing_images(similar_images, num_samples=5):\n",
    "    \"\"\"Displays pairs of most similar images from different classes.\"\"\"\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(8, 10))\n",
    "    \n",
    "    for i, (img1, img2, class1, class2, _) in enumerate(similar_images[:num_samples]):\n",
    "        img1 = image.load_img(img1)\n",
    "        img2 = image.load_img(img2)\n",
    "        \n",
    "        axes[i, 0].imshow(img1)\n",
    "        axes[i, 0].axis('off')\n",
    "        axes[i, 0].set_title(f\"Class: {class1}\")\n",
    "\n",
    "        axes[i, 1].imshow(img2)\n",
    "        axes[i, 1].axis('off')\n",
    "        axes[i, 1].set_title(f\"Class: {class2}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ==================== 5Ô∏è‚É£ Run the Analysis ====================\n",
    "# Set your dataset path (folder with class subfolders)\n",
    "dataset_path = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\train_dir\"\n",
    "\n",
    "# Find similar images\n",
    "similar_images = find_similar_images(dataset_path, threshold=0.2)\n",
    "\n",
    "# Show top 5 confusing image pairs\n",
    "if similar_images:\n",
    "    show_confusing_images(similar_images, num_samples=5)\n",
    "else:\n",
    "    print(\"No highly similar images found between different classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from images using EfficientNetB0 and t-SNE visualization\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set dataset path\n",
    "DATASET_PATH = r\"D:\\skin_disease_detection\\backend\\own_data\\base_dir\\train_dir\"  # Change to your train_dir path\n",
    "\n",
    "# Get class names\n",
    "class_names = sorted(os.listdir(DATASET_PATH))\n",
    "num_classes = len(class_names)\n",
    "print(f\"‚úÖ Found {num_classes} classes: {class_names}\")\n",
    "\n",
    "# Load pre-trained EfficientNetB0 (Feature Extractor)\n",
    "base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, pooling=\"avg\")\n",
    "\n",
    "# Prepare lists to store data\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Load images and extract features in batches\n",
    "for class_index, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(DATASET_PATH, class_name)\n",
    "    image_files = os.listdir(class_path)[:50]  # Take only 50 images per class (for speed)\n",
    "    \n",
    "    batch_images = []\n",
    "    batch_labels = []\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=f\"Processing {class_name}\", leave=False):\n",
    "        img_path = os.path.join(class_path, img_file)\n",
    "        \n",
    "        # Load image and preprocess\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        batch_images.append(img_array)\n",
    "        batch_labels.append(class_index)\n",
    "\n",
    "    # Convert batch to NumPy array\n",
    "    batch_images = np.array(batch_images)\n",
    "    \n",
    "    # Extract features in batch mode (faster)\n",
    "    batch_features = base_model.predict(batch_images, batch_size=16)\n",
    "    \n",
    "    # Store results\n",
    "    features.extend(batch_features)\n",
    "    labels.extend(batch_labels)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"‚úÖ Feature extraction completed. Shape:\", features.shape)\n",
    "\n",
    "# Reduce dimensions using t-SNE\n",
    "print(\"üîÑ Running t-SNE (this may take a few minutes)...\")\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "features_2d = tsne.fit_transform(features)\n",
    "\n",
    "print(\"‚úÖ t-SNE completed. Plotting results...\")\n",
    "\n",
    "# Plot the t-SNE visualization\n",
    "plt.figure(figsize=(10, 7))\n",
    "palette = sns.color_palette(\"hsv\", num_classes)\n",
    "sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], hue=labels, palette=palette, alpha=0.7)\n",
    "plt.legend(title=\"Classes\", labels=class_names)\n",
    "plt.title(\"t-SNE Visualization of Skin Disease Dataset\")\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Process completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn-dis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
