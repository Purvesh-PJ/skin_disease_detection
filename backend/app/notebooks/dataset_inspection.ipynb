{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET INSPECTION\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define metadata path and image directories\n",
    "metadata_path = r'D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "image_dir_1 = r'D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_1'\n",
    "image_dir_2 = r'D:\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_2'\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Inspect the first few rows\n",
    "print(\"##### Inspect The First Few Rows #####\")\n",
    "print(metadata.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check data types\n",
    "data_types = metadata.dtypes\n",
    "print(\"##### Data Types ##### \\n\", data_types)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = metadata.isnull().sum()\n",
    "print(\"##### Missing Values In Columns ##### \\n\", missing_values)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check Unknown Valuses In \"SEX\" and \"LOCALIZATION\" Columns\n",
    "print(\"##### Checking 'unknown' values in 'SEX' and 'LOCALIZATION' columns #####\")\n",
    "if 'unknown' in metadata['sex'].values:\n",
    "    print(\"'unknown' exists in 'sex' column.\")\n",
    "else:\n",
    "    print(\"'unknown' does not exist in 'sex' column.\")\n",
    "\n",
    "if 'unknown' in metadata['localization'].values:\n",
    "    print(\"'unknown' exists in 'localization' column.\")\n",
    "else:\n",
    "    print(\"'unknown' does not exist in 'localization' column.\")\n",
    "\n",
    "# Check for duplicate rows in metadata\n",
    "print(\"\\n\")\n",
    "print(\"##### Checking Duplicate Rows #####\")\n",
    "duplicate_count = metadata.duplicated().sum()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Duplicate rows found: {duplicate_count}. Removing duplicates...\")\n",
    "    # metadata.drop_duplicates(inplace=True)\n",
    "    # print(\"Duplicate rows removed.\")\n",
    "else:\n",
    "    print(\"No duplicate rows found. No action taken.\")\n",
    "\n",
    "# Verify that all images listed in the metadata are present in the folders\n",
    "print(\"\\n\")\n",
    "print(\"##### Checking Missing Images In Folders #####\")\n",
    "image_ids = set(metadata['image_id'])\n",
    "all_image_files = set(os.listdir(image_dir_1) + os.listdir(image_dir_2))\n",
    "missing_images = [img_id for img_id in image_ids if f\"{img_id}.jpg\" not in all_image_files]\n",
    "if missing_images:\n",
    "    print(f\"Missing images: {missing_images}\")\n",
    "else:\n",
    "    print(\"All images are accounted for.\")\n",
    "\n",
    "# Check for duplicate image_id values\n",
    "print(\"\\n\")\n",
    "# Check for rows with age = 0.0\n",
    "print(\"##### Checking for invalid ages (0.0) #####\")\n",
    "invalid_age_rows = metadata[metadata['age'] == 0.0]\n",
    "print(f\"Number of rows with invalid age: {len(invalid_age_rows)}\")\n",
    "\n",
    "if len(invalid_age_rows) > 0:\n",
    "    print(\"\\nRows with invalid age:\")\n",
    "    print(invalid_age_rows)  # Display all rows with invalid age\n",
    "else:\n",
    "    print(\"No invalid ages found.\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Basic statistics of the dataset\n",
    "print(\"\\n\")\n",
    "print(\"##### Statistics of the dataset #####\")\n",
    "print(metadata.describe(include='all'))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET VISUALIZATION\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "metadata_path = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "image_dir_1 = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_1'\n",
    "image_dir_2 = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_images_part_2'\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Visualize the distribution of diseases\n",
    "print(\"\\n\")\n",
    "print(\"##### Displaying Distribution of Diseases (Lesion) #####\")\n",
    "sns.countplot(data=metadata, x='dx')\n",
    "plt.title(\"Distribution of Skin Diseases in HAM10000 Dataset\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Display sample images\n",
    "print(\"##### Displaying sample images #####\")\n",
    "def display_sample_images(image_dir, num_samples=5):\n",
    "    sample_files = os.listdir(image_dir)[:num_samples]\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, filename in enumerate(sample_files):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(image_path)\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "display_sample_images(image_dir_1)\n",
    "display_sample_images(image_dir_2)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Additional Checks and Visualizations\n",
    "\n",
    "# Correlation Analysis\n",
    "numeric_metadata = metadata.select_dtypes(include=['float64', 'int64'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(numeric_metadata.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Outliers Detection\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='age', data=metadata)\n",
    "plt.title('Age Outliers')\n",
    "plt.show()\n",
    "\n",
    "# Data Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.pairplot(metadata, hue='dx')\n",
    "plt.title('Pairplot of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET MANIPULATION\n",
    "\n",
    "import pandas as pd\n",
    "# Define metadata path and image directories\n",
    "metadata_path = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# HANDLING [ UNKNOWN, MISING] VALUES IN \"SEX\" AND \"LOCALIZATION\" COLUMNS\n",
    "if 'unknown' in metadata['sex'].values:\n",
    "    metadata['sex'].replace('unknown', metadata['sex'].mode()[0], inplace=True)\n",
    "    print(f\"'unknown' in 'sex' replaced with mode: {metadata['sex'].mode()[0]}\")\n",
    "\n",
    "if 'unknown' in metadata['localization'].values:\n",
    "    metadata['localization'].replace('unknown', metadata['localization'].mode()[0], inplace=True)\n",
    "    print(f\"'unknown' in 'localization' replaced with mode: {metadata['localization'].mode()[0]}\")\n",
    "\n",
    "# Check for rows with age = 0.0\n",
    "print(\"##### Checking for invalid ages (0.0) #####\")\n",
    "invalid_age_rows = metadata[metadata['age'] == 0.0]\n",
    "print(f\"Number of rows with invalid age: {len(invalid_age_rows)}\")\n",
    "\n",
    "if len(invalid_age_rows) > 0:\n",
    "    print(\"\\nRows with invalid age:\")\n",
    "    print(invalid_age_rows)  # Display all rows with invalid age\n",
    "\n",
    "    # Replace 0.0 with the median age\n",
    "    median_age = metadata[metadata['age'] > 0.0]['age'].median()\n",
    "    metadata['age'] = metadata['age'].replace(0.0, median_age)\n",
    "    print(f\"Invalid ages replaced with the median age: {median_age:.2f}\")\n",
    "else:\n",
    "    print(\"No invalid ages found.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Save the cleaned metadata\n",
    "metadata.to_csv(metadata_path, index=False)\n",
    "print(\"Cleaned metadata saved to metadata.csv : {metadata_path}\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING CLASS WEIGHTS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "metadata_path = r'D:\\projects\\skin_disease_detection\\backend\\data\\Ham10000\\HAM10000_metadata.csv'\n",
    "dataset = pd.read_csv(metadata_path)\n",
    "labels = dataset['dx']\n",
    "\n",
    "print(labels.head())\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Define class labels and counts from your dataset\n",
    "classes = ['bkl', 'nv', 'df', 'mel', 'vasc', 'bcc', 'akiec']\n",
    "class_counts = [1099, 6705, 115, 1113, 142, 514, 327]  # Replace with your dataset values\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(classes), y=classes)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "print(\"Class Weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VISUALIZATION : DATA2 CLASS DISTRIBUTION PLOT\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "def plot_class_distribution(dataset_path):\n",
    "    \"\"\"\n",
    "    Visualizes the class distribution from the dataset folder structure.\n",
    "    \n",
    "    :param dataset_path: Path to the dataset directory containing class subfolders.\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    \n",
    "    # Iterate through each class folder\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_folder = os.path.join(dataset_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_counts[class_name] = len(os.listdir(class_folder))\n",
    "    \n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()), palette=\"viridis\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Number of Images\")\n",
    "    plt.title(\"Dataset Class Distribution\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (update with your actual dataset path)\n",
    "dataset_path = r\"D:\\skin_disease_detection\\backend\\data2\\base_dir\\train_dir\"\n",
    "plot_class_distribution(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SCRIPT INCREASE ALL CLASSES 200 PLUS FOR BALANCE VAL_DIR IN DATA2\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_images_balanced(val_dir, target_count=500, max_variants_per_image=5):\n",
    "    \"\"\"\n",
    "    Augments images inside val_dir while ensuring balanced class distribution.\n",
    "    - Each class will have at least `target_count` images.\n",
    "    - Prevents excessive duplication from a single image.\n",
    "    - Saves augmented images with `_X_randomnumber.jpg` format (X = class 0-6).\n",
    "    \"\"\"\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "\n",
    "    for class_index, class_name in enumerate(os.listdir(val_dir)):\n",
    "        class_path = os.path.join(val_dir, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-folder files\n",
    "\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "        num_existing = len(images)\n",
    "\n",
    "        if num_existing >= target_count:\n",
    "            print(f\"Skipping {class_name}, already has {num_existing} images.\")\n",
    "            continue\n",
    "\n",
    "        num_needed = target_count - num_existing\n",
    "        print(f\"Generating {num_needed} images for class: {class_name}\")\n",
    "\n",
    "        # Determine how many times each image should be augmented\n",
    "        augmentation_distribution = np.full(len(images), num_needed // len(images))\n",
    "        augmentation_distribution[:num_needed % len(images)] += 1  # Spread remainder\n",
    "\n",
    "        for img_path, aug_count in zip(images, augmentation_distribution):\n",
    "            if aug_count == 0:\n",
    "                continue\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "            i = 0\n",
    "            for batch in datagen.flow(img, batch_size=1):\n",
    "                random_number = np.random.randint(10000, 99999)\n",
    "                filename = f\"_{class_index}_{random_number}.jpg\"\n",
    "                save_path = os.path.join(class_path, filename)\n",
    "\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(batch[0].astype('uint8'), cv2.COLOR_RGB2BGR))\n",
    "                i += 1\n",
    "                if i >= aug_count or i >= max_variants_per_image:\n",
    "                    break  # Prevent excessive augmentation per image\n",
    "\n",
    "    print(\"Augmentation completed.\")\n",
    "\n",
    "# Example usage:\n",
    "val_directory = r\"D:\\skin_disease_detection\\backend\\data2\\base_dir\\val_dir\"\n",
    "augment_images_balanced(val_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS SCRIPT ONLY INCREASE CLASSES WHOSE LESS THAN 200 AND BALANCE VAL_DIR IN DATA2\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_images_balanced(val_dir, min_target=450, max_variants_per_image=10):\n",
    "    \"\"\"\n",
    "    Augments images in `val_dir` to ensure every class has at least `min_target` images.\n",
    "    - Classes with fewer images will get more augmentation.\n",
    "    - Limits excessive duplication per image using `max_variants_per_image`.\n",
    "    \"\"\"\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=25,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "\n",
    "    for class_index, class_name in enumerate(os.listdir(val_dir)):\n",
    "        class_path = os.path.join(val_dir, class_name)\n",
    "\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-folder files\n",
    "\n",
    "        images = [os.path.join(class_path, img) for img in os.listdir(class_path)]\n",
    "        num_existing = len(images)\n",
    "\n",
    "        if num_existing >= min_target:\n",
    "            print(f\"âœ… Skipping {class_name}, already has {num_existing} images.\")\n",
    "            continue\n",
    "\n",
    "        num_needed = min_target - num_existing\n",
    "        print(f\"ðŸ”„ Generating {num_needed} images for class: {class_name}\")\n",
    "\n",
    "        # Adjust max augmentations per image based on how few images we have\n",
    "        per_image_limit = min(max_variants_per_image, (num_needed // max(1, num_existing)) + 1)\n",
    "\n",
    "        for img_path in images:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "            img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "            i = 0\n",
    "            for batch in datagen.flow(img, batch_size=1):\n",
    "                random_number = np.random.randint(10000, 99999)\n",
    "                filename = f\"_{class_index}_{random_number}.jpg\"\n",
    "                save_path = os.path.join(class_path, filename)\n",
    "\n",
    "                cv2.imwrite(save_path, cv2.cvtColor(batch[0].astype('uint8'), cv2.COLOR_RGB2BGR))\n",
    "                i += 1\n",
    "                if i >= per_image_limit:\n",
    "                    break  # Stop once enough images are generated\n",
    "\n",
    "    print(\"âœ… Augmentation completed with balanced validation set.\")\n",
    "\n",
    "# Example usage:\n",
    "val_directory = r\"D:\\skin_disease_detection\\backend\\data2\\base_dir\\val_dir\"\n",
    "augment_images_balanced(val_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn-dis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
